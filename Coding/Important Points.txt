 --> GCD(a,b) = GCD(a-b,b) where a>b
 --> GCD(a,b) = GCD(b,a%b) where a>b
 --> a^b ==>{
              a*a^{b-1}   , if b&1!=0
              (a^2)*a^b/2  , if b&1===0
          }

 --> {a+b}%n => (a%n + b%n)%n;  same for { - and * }

 --> (a / b) % m = (a * (inverse of b if exists)) % m

 --> The modular inverse of a mod m exists only if a and m are relatively prime i.e. gcd(a, m) = 1.
Hence, for finding inverse of a under modulo m,
if (a x b) mod m = 1 then b is modular inverse of a.
Example:
a = 5, m = 7
(5 x 3) % 7 = 1
hence, 3 is modulo inverse of 5 under 7.

 --> Josephus Problem : f(n,k) = (f(n-1,k)+k)%n; {If index start from 0}

 --> String is palindrome : Use recursion , check 0th and last index if they are equal call same fn for index 1 to length-1


 --> Set  = [a,b,c]
power_set_size = pow(2, 3) = 8
Run for binary counter = 000 to 111

Value of Counter            Subset
   000                    -> Empty set
   001                    -> a
   010                    -> b
   011                    -> ab
   100                    -> c
   101                    -> ac
   110                    -> bc
   111                    -> abc


--> When question is saying to use space mostly their hashmap or memoization is used!

--> In C (and many other languages like C++, Java etc), 2-D arrays are stored in row-major order.(though Pascal and Fortran follows column major order)

--> Prefix & Suffix sum array

--> tail-recursive is better than a non-tail recursive as tail-recursion can be optimized by modern compilers. Modern compiler basically does tail call elimination to optimize the tail-recursive code. 

--> QuickSort is also tail recursive , MergeSort is not tail recursive

 --> Function stack frame management in Tail Call Elimination : 
Recursion uses a stack to keep track of function calls. With every function call, a new frame is pushed onto the stack which contains local variables and data of that call. Let’s say one stack frame requires O(1) i.e, constant memory space, then for N recursive call memory required would be O(N). 

Tail call elimination reduces the space complexity of recursion from O(N) to O(1). As function call is eliminated, no new stack frames are created and the function is executed in constant memory space. 

It is possible for the function to execute in constant memory space because, in tail recursive function, there are no statements after call statement so preserving state and frame of parent function is not required. Child function is called and finishes immediately, it doesn’t have to return control back to the parent function. 

As no computation is performed on the returned value and no statements are left for execution, the current frame can be modified as per the requirements of the current function call. So there is no need to preserve stack frames of previous function calls and function executes in constant memory space. This makes tail recursion faster and memory-friendly.

-->  The floor of the square root of x cannot be more than x/2 when x > 1.

LowerTriangular Matrix: 
  --> non-zero elements = (n*(n+1))/2;
  --> zero elements = n^2 - (n*(n+1))/2;
  --> we store non-zero elements in an array 
  --> Row-Major Mapping = arrayIndex for corresponding eleemnt Matrix[i,j] = array[(i*(i-1))/2+(j-1)]
   --> Column-Major Mapping = arrayIndex for corresponding eleemnt Matrix[i,j] = array[(N(j-1)-((j-1)*(j-2))/2)+(i-j)]


UpperTriangular Matrix: 
  --> non-zero elements = (n*(n+1))/2;
  --> zero elements = n^2 - (n*(n+1))/2;
  --> we store non-zero elements in an array 
  --> Row-Major Mapping = array[(N(i-1)-((i-1)*(i-2))/2)+(j-i)]
   --> Column-Major Mapping = arrayIndex for corresponding elemnt Matrix[i,j] = array[(j*(j-1))/2+(i-1)]


--> Symmetric-Matrix can also store in LowerTriangular or UpperTriangular matrix ...


TriDiagonal Matrix:
  --> non-zero elements = 3*N-2;
  --> Matrix[i,j]: 
        --> Case1 = if(i-j==1) ==> array[i-1]
        --> Case2 = if(i-j==0) ==> array[n-1+i-1]
        --> Case3 = if(j-i==1) ==> array[2*n-1+i-1]

Toeplitz Matrix:
   --> Matrix[i,j]:
         --> Case1 = if(i<=j) ==> array[j-i]
         --> Case2 = if(i>j)  ==> N + i-j-1

Lets look at the number of valid possibilities for A^B.


For B = 2, number of possibilities = sqrt(INT_MAX) = sqrt(2^31 - 1) < 2^16.
For B = 3, number of possibilities = INT_MAX**1/3 < 2^11
For B = 4, number of possibilities = INT_MAX**1/4 < 2^8
.
.
.
For B = 32, number of possibilities = 0 ( Not considering 1 as its considered in the first case, and 2^32 exceeds INT_MAX ). 

So, the total number of possibilities are less than 10^5.

Now, we just need to iterate on these possibilities and see if we find X = A^B.



Note: 
Some interesting fact about Prime numbers 

Two is the only even Prime number.
Every prime number can be represented in form of 6n+1 or 6n-1 except the prime number 2 and 3, where n is a natural number.
Two and Three are only two consecutive natural numbers that are prime.
Goldbach Conjecture: Every even integer greater than 2 can be expressed as the sum of two primes.
Wilson Theorem: Wilson’s theorem states that a natural number p > 1 is a prime number if and only if
(p - 1) ! ≡  -1   mod p 
OR  (p - 1) ! ≡  (p-1) mod p
Fermat’s Little Theorem: If n is a prime number, then for every a, 1 <= a < n,
an-1 ≡ 1 (mod n)
OR 
an-1 % n = 1
Prime Number Theorem: The probability that a given, randomly chosen number n is prime is inversely proportional to its number of digits, or to the logarithm of n.
Lemoine’s Conjecture: Any odd integer greater than 5 can be expressed as a sum of an odd prime (all primes other than 2 are odd) and an even semiprime. A semiprime number is a product of two prime numbers. This is called Lemoine’s conjecture.


To find prime factors of a number such that N = prime1*prime2

Use:  ----> N = X^2 - Y^2  and X = Math.sqrt(N + Y^2)


Fermat’s Primality Test --> is N is prime = if all a^N-a is a multiple of N for 1<=a<N
Drawbacks --> **> Not 100% accurate 
              **> Time consuming for large numbers


**> Divisors:
If we look carefully, all the divisors are present in pairs. For example if n = 100, then the various pairs of divisors are: (1,100), (2,50), (4,25), (5,20), (10,10)
Using this fact we could speed up our program significantly. 
We, however, have to be careful if there are two equal divisors as in the case of (10, 10). 



Note ==> **>  The divisors of a number other than 1 and the number itself are called the factors of that number. 

**>  Prime number has no factors and it will have only two divisors. They are 1 and the number itself. 

1)  "1" has only one divisor, that is 1. So 1 is neither prime nor composite.  

2)  1 and number itself are divisors of any number. 

3)  Is there any number which has no divisor ? No, because 1 is a divisor of all numbers.

4) Some numbers have more than two divisors. Those numbers are called as composite numbers. 

5) Some numbers have exactly two divisors. Those numbers are called as prime numbers. 

6)  Prime numbers has no factors. 

7) All factors are divisors, but all divisors are not factors. 


TODO:  Taylor Series using Recursion
TODO:  Taylor Series using Horner's Rule
TODO:  Fibonnacci Series using Recursion & Memoization 
TODO:  nCr using Recursion and Pascal Triangle 
TODO:  Tower Of Hanoi using Recursion
TODO:  Total Set Bits in natural numbers