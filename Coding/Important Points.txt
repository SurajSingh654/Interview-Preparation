 --> GCD(a,b) = GCD(a-b,b) where a>b
 --> GCD(a,b) = GCD(b,a%b) where a>b
 --> a^b ==>{
              a*a^{b-1}   , if b&1!=0
              (a^2)*a^b/2  , if b&1===0
          }

 --> {a+b}%n => (a%n + b%n)%n;  same for { - and * }

 --> (a / b) % m = (a * (inverse of b if exists)) % m

 --> The modular inverse of a mod m exists only if a and m are relatively prime i.e. gcd(a, m) = 1.
Hence, for finding inverse of a under modulo m,
if (a x b) mod m = 1 then b is modular inverse of a.
Example:
a = 5, m = 7
(5 x 3) % 7 = 1
hence, 3 is modulo inverse of 5 under 7.

 --> Josephus Problem : f(n,k) = (f(n-1,k)+k)%n; {If index start from 0}

 --> String is palindrome : Use recursion , check 0th and last index if they are equal call same fn for index 1 to length-1


 --> Set  = [a,b,c]
power_set_size = pow(2, 3) = 8
Run for binary counter = 000 to 111

Value of Counter            Subset
   000                    -> Empty set
   001                    -> a
   010                    -> b
   011                    -> ab
   100                    -> c
   101                    -> ac
   110                    -> bc
   111                    -> abc


--> When question is saying to use space mostly their hashmap or memoization is used!

--> In C (and many other languages like C++, Java etc), 2-D arrays are stored in row-major order.(though Pascal and Fortran follows column major order)

--> Prefix & Suffix sum array

--> tail-recursive is better than a non-tail recursive as tail-recursion can be optimized by modern compilers. Modern compiler basically does tail call elimination to optimize the tail-recursive code. 

--> QuickSort is also tail recursive , MergeSort is not tail recursive

 --> Function stack frame management in Tail Call Elimination : 
Recursion uses a stack to keep track of function calls. With every function call, a new frame is pushed onto the stack which contains local variables and data of that call. Let’s say one stack frame requires O(1) i.e, constant memory space, then for N recursive call memory required would be O(N). 

Tail call elimination reduces the space complexity of recursion from O(N) to O(1). As function call is eliminated, no new stack frames are created and the function is executed in constant memory space. 

It is possible for the function to execute in constant memory space because, in tail recursive function, there are no statements after call statement so preserving state and frame of parent function is not required. Child function is called and finishes immediately, it doesn’t have to return control back to the parent function. 

As no computation is performed on the returned value and no statements are left for execution, the current frame can be modified as per the requirements of the current function call. So there is no need to preserve stack frames of previous function calls and function executes in constant memory space. This makes tail recursion faster and memory-friendly.

-->  The floor of the square root of x cannot be more than x/2 when x > 1.

LowerTriangular Matrix: 
  --> non-zero elements = (n*(n+1))/2;
  --> zero elements = n^2 - (n*(n+1))/2;
  --> we store non-zero elements in an array 
  --> Row-Major Mapping = arrayIndex for corresponding eleemnt Matrix[i,j] = array[(i*(i-1))/2+(j-1)]
   --> Column-Major Mapping = arrayIndex for corresponding eleemnt Matrix[i,j] = array[(N(j-1)-((j-1)*(j-2))/2)+(i-j)]


UpperTriangular Matrix: 
  --> non-zero elements = (n*(n+1))/2;
  --> zero elements = n^2 - (n*(n+1))/2;
  --> we store non-zero elements in an array 
  --> Row-Major Mapping = array[(N(i-1)-((i-1)*(i-2))/2)+(j-i)]
   --> Column-Major Mapping = arrayIndex for corresponding elemnt Matrix[i,j] = array[(j*(j-1))/2+(i-1)]


--> Symmetric-Matrix can also store in LowerTriangular or UpperTriangular matrix ...


TriDiagonal Matrix:
  --> non-zero elements = 3*N-2;
  --> Matrix[i,j]: 
        --> Case1 = if(i-j==1) ==> array[i-1]
        --> Case2 = if(i-j==0) ==> array[n-1+i-1]
        --> Case3 = if(j-i==1) ==> array[2*n-1+i-1]

Toeplitz Matrix:
   --> Matrix[i,j]:
         --> Case1 = if(i<=j) ==> array[j-i]
         --> Case2 = if(i>j)  ==> N + i-j-1

Lets look at the number of valid possibilities for A^B.


For B = 2, number of possibilities = sqrt(INT_MAX) = sqrt(2^31 - 1) < 2^16.
For B = 3, number of possibilities = INT_MAX**1/3 < 2^11
For B = 4, number of possibilities = INT_MAX**1/4 < 2^8
.
.
.
For B = 32, number of possibilities = 0 ( Not considering 1 as its considered in the first case, and 2^32 exceeds INT_MAX ). 

So, the total number of possibilities are less than 10^5.

Now, we just need to iterate on these possibilities and see if we find X = A^B.


TODO:  Taylor Series using Recursion
TODO:  Taylor Series using Horner's Rule
TODO:  Fibonnacci Series using Recursion & Memoization 
TODO:  nCr using Recursion and Pascal Triangle 
TODO:  Tower Of Hanoi using Recursion
TODO:  Total Set Bits in natural numbers